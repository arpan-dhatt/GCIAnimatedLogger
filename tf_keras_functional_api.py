# -*- coding: utf-8 -*-
"""TF Keras Functional API

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1izu2IiXXyywfqydPqH89Zo0gDnSB5j6T

# TF Keras Functional API
# Now being used for testing AnimatedLogger
"""

import tensorflow as tf
from tensorflow.keras import layers
tf.version.VERSION

"""# Loading Data"""

((train_data,train_labels),(eval_data,eval_labels)) = tf.keras.datasets.mnist.load_data();

"""Visualizing the data"""

print("Training data has a shape of",train_data.shape,"\nTraining labels has a shape of",train_labels.shape)
print()
print("Evaluation data has a shape of",eval_data.shape,"\nEvaluation labels has a shape of",eval_data.shape)

"""Looks like we will need to do one-hot encoding for the labels ourselves :(
# Building the Model
This is a very simple convolutional neural network.
"""

#remove old network
tf.keras.backend.clear_session()

IMG_SIZE = train_data.shape[1]
NUM_CLASSES = 10;

#start with input(batch size omitted):
inputs = layers.Input(shape=(IMG_SIZE,IMG_SIZE,1))

#convolutional layers and max pooling
conv1 = layers.Conv2D(32,(3,3),activation="relu")(inputs)
maxp1 = layers.MaxPooling2D((2,2))(conv1)
conv2 = layers.Conv2D(64,(3,3),activation="relu")(maxp1)
maxp2 = layers.MaxPooling2D((2,2))(conv2)
conv3 = layers.Conv2D(64,(3,3),activation="relu")(maxp2)

#flatten 3D data for Dense part of network
flat = layers.Flatten()(conv3)

#dense part of network
dense1 = layers.Dense(64,activation="relu")(flat)

#final part with softmax b/c of categorical data
outputs = layers.Dense(NUM_CLASSES,activation="softmax")(dense1)

#instantiate model
model = tf.keras.Model(inputs=inputs,outputs=outputs)

model.summary()

"""# Setting up data for training"""

#normalize training data and evaluation data
train_data = (train_data-train_data.mean())/train_data.std()
eval_data = (eval_data-eval_data.mean())/eval_data.std()
train_data = train_data.reshape((train_data.shape[0],IMG_SIZE,IMG_SIZE,1))
eval_data = eval_data.reshape((eval_data.shape[0],IMG_SIZE,IMG_SIZE,1))
print("Training Data: mean={} std={}".format(train_data.mean(),train_data.std()))
print("Evaluation Data: mean={} std={}".format(eval_data.mean(),eval_data.std()))

#convert labels to one-hot
train_labels = tf.one_hot(train_labels,10);
eval_labels = tf.one_hot(eval_labels,10);
print("Training Labels:")
print(train_labels)
print("Evaluation Labels:")
print(eval_labels)

"""The data has been normalized and the labels have been one-hot encoded! Time to compile the model!"""

model.compile(optimizer="adam",loss="categorical_crossentropy",metrics=["accuracy"],)

"""Importing my AnimatedLogger Callback"""
from animated_logger import AnimatedLogger
"""Training the model"""

model.fit(x=train_data,y=train_labels,batch_size=1024,epochs=2,validation_split=0.05,verbose=0,callbacks=[AnimatedLogger()])

"""Now that the model is trained, let's use our evaluation data to see how good it is."""

out = model.evaluate(x=eval_data,y=eval_labels,batch_size=128,verbose=0)
print("Accuracy on Evaluation Data:",out[1]*100,"%")

